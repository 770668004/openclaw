#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ€èƒ½å®¡è®¡æ¨¡å— - ä¸¥æ ¼çš„å®‰å…¨å’Œé€»è¾‘å®¡è®¡
"""

import os
import json
import hashlib
import re
from typing import Dict, List, Tuple, Optional
from datetime import datetime

class SkillAuditor:
    """æŠ€èƒ½å®¡è®¡å™¨ - è´Ÿè´£å¯¹æŠ€èƒ½è¿›è¡Œå®‰å…¨æ€§å’Œé€»è¾‘æ€§å®¡è®¡"""
    
    def __init__(self):
        self.security_rules = {
            'forbidden_patterns': [
                r'rm\s+-rf',  # ç¦æ­¢å±é™©çš„åˆ é™¤å‘½ä»¤
                r'sudo\s+.*',  # éœ€è¦è°¨æ…Žå¤„ç†çš„sudoå‘½ä»¤
                r'eval\s*\(.*\)',  # ç¦æ­¢eval
                r'exec\s*\(.*\)',  # ç¦æ­¢åŠ¨æ€æ‰§è¡Œ
                r'os\.system\s*\(.*\)',  # ç¦æ­¢ç³»ç»Ÿå‘½ä»¤æ‰§è¡Œ
            ],
            'required_patterns': [
                r'# Security:',  # å¿…é¡»åŒ…å«å®‰å…¨è¯´æ˜Ž
                r'# When to Use',  # å¿…é¡»åŒ…å«ä½¿ç”¨åœºæ™¯
                r'# When NOT to Use',  # å¿…é¡»åŒ…å«ç¦æ­¢ä½¿ç”¨åœºæ™¯
            ],
            'sensitive_operations': [
                'file_write', 'network_request', 'system_command',
                'credential_access', 'data_modification'
            ]
        }
        
    def audit_skill_file(self, skill_path: str) -> Dict[str, any]:
        """
        å®¡è®¡å•ä¸ªæŠ€èƒ½æ–‡ä»¶
        
        Args:
            skill_path: æŠ€èƒ½æ–‡ä»¶è·¯å¾„
            
        Returns:
            å®¡è®¡ç»“æžœå­—å…¸
        """
        audit_result = {
            'skill_name': os.path.basename(os.path.dirname(skill_path)),
            'file_path': skill_path,
            'security_score': 0,
            'logic_score': 0,
            'issues': [],
            'recommendations': [],
            'is_safe_to_upgrade': False,
            'audit_timestamp': datetime.now().isoformat()
        }
        
        try:
            with open(skill_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # å®‰å…¨æ€§å®¡è®¡
            security_issues = self._check_security_violations(content)
            audit_result['issues'].extend(security_issues)
            
            # é€»è¾‘æ€§å®¡è®¡
            logic_issues = self._check_logic_consistency(content)
            audit_result['issues'].extend(logic_issues)
            
            # è®¡ç®—è¯„åˆ†
            audit_result['security_score'] = max(0, 100 - len(security_issues) * 10)
            audit_result['logic_score'] = max(0, 100 - len(logic_issues) * 10)
            
            # ç”Ÿæˆå»ºè®®
            audit_result['recommendations'] = self._generate_recommendations(
                security_issues, logic_issues
            )
            
            # åˆ¤æ–­æ˜¯å¦å®‰å…¨å‡çº§
            audit_result['is_safe_to_upgrade'] = (
                audit_result['security_score'] >= 80 and 
                audit_result['logic_score'] >= 70 and
                not any('critical' in issue.get('severity', '') for issue in audit_result['issues'])
            )
            
        except Exception as e:
            audit_result['issues'].append({
                'type': 'file_error',
                'severity': 'critical',
                'message': f'æ— æ³•è¯»å–æŠ€èƒ½æ–‡ä»¶: {str(e)}'
            })
            
        return audit_result
    
    def _check_security_violations(self, content: str) -> List[Dict[str, any]]:
        """æ£€æŸ¥å®‰å…¨è¿è§„"""
        issues = []
        
        # æ£€æŸ¥ç¦æ­¢æ¨¡å¼
        for pattern in self.security_rules['forbidden_patterns']:
            matches = re.finditer(pattern, content, re.IGNORECASE)
            for match in matches:
                issues.append({
                    'type': 'forbidden_pattern',
                    'severity': 'critical' if 'rm -rf' in pattern else 'high',
                    'message': f'å‘çŽ°ç¦æ­¢çš„æ¨¡å¼: {match.group()}',
                    'line_number': content[:match.start()].count('\n') + 1
                })
        
        # æ£€æŸ¥å¿…éœ€æ¨¡å¼
        for pattern in self.security_rules['required_patterns']:
            if not re.search(pattern, content, re.IGNORECASE):
                issues.append({
                    'type': 'missing_required_pattern',
                    'severity': 'medium',
                    'message': f'ç¼ºå°‘å¿…éœ€çš„å®‰å…¨æ–‡æ¡£: {pattern}'
                })
        
        # æ£€æŸ¥æ•æ„Ÿæ“ä½œ
        sensitive_ops = self._detect_sensitive_operations(content)
        for op in sensitive_ops:
            issues.append({
                'type': 'sensitive_operation',
                'severity': 'medium',
                'message': f'æ£€æµ‹åˆ°æ•æ„Ÿæ“ä½œ: {op}',
                'requires_confirmation': True
            })
            
        return issues
    
    def _check_logic_consistency(self, content: str) -> List[Dict[str, any]]:
        """æ£€æŸ¥é€»è¾‘ä¸€è‡´æ€§"""
        issues = []
        
        # æ£€æŸ¥æè¿°å®Œæ•´æ€§
        if 'description:' not in content:
            issues.append({
                'type': 'missing_description',
                'severity': 'high',
                'message': 'æŠ€èƒ½ç¼ºå°‘æè¿°å­—æ®µ'
            })
        
        # æ£€æŸ¥åŠŸèƒ½è¯´æ˜Ž
        if '## When to Use' not in content or '## When NOT to Use' not in content:
            issues.append({
                'type': 'incomplete_usage_guide',
                'severity': 'medium',
                'message': 'ä½¿ç”¨æŒ‡å—ä¸å®Œæ•´ï¼Œç¼ºå°‘ä½¿ç”¨åœºæ™¯æˆ–ç¦æ­¢åœºæ™¯è¯´æ˜Ž'
            })
        
        # æ£€æŸ¥ä»£ç ç¤ºä¾‹
        if '```' not in content:
            issues.append({
                'type': 'missing_examples',
                'severity': 'low',
                'message': 'ç¼ºå°‘ä½¿ç”¨ç¤ºä¾‹'
            })
        
        return issues
    
    def _detect_sensitive_operations(self, content: str) -> List[str]:
        """æ£€æµ‹æ•æ„Ÿæ“ä½œ"""
        detected_ops = []
        
        # æ–‡ä»¶å†™å…¥æ“ä½œ
        if re.search(r'(write|create|overwrite).*file', content, re.IGNORECASE):
            detected_ops.append('file_write')
            
        # ç½‘ç»œè¯·æ±‚
        if re.search(r'(curl|wget|http|fetch|request)', content, re.IGNORECASE):
            detected_ops.append('network_request')
            
        # ç³»ç»Ÿå‘½ä»¤
        if re.search(r'(bash|sh|command|exec)', content, re.IGNORECASE):
            detected_ops.append('system_command')
            
        # å‡­æ®è®¿é—®
        if re.search(r'(password|token|key|credential|auth)', content, re.IGNORECASE):
            detected_ops.append('credential_access')
            
        # æ•°æ®ä¿®æ”¹
        if re.search(r'(edit|modify|delete|remove|update)', content, re.IGNORECASE):
            detected_ops.append('data_modification')
            
        return detected_ops
    
    def _generate_recommendations(self, security_issues: List, logic_issues: List) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # å®‰å…¨å»ºè®®
        critical_issues = [i for i in security_issues if i.get('severity') == 'critical']
        if critical_issues:
            recommendations.append("ðŸš¨ ç«‹å³ä¿®å¤å…³é”®å®‰å…¨é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯ç¦æ­¢çš„å±é™©å‘½ä»¤æ¨¡å¼")
            
        high_issues = [i for i in security_issues if i.get('severity') == 'high']
        if high_issues:
            recommendations.append("âš ï¸ ä¿®å¤é«˜é£Žé™©å®‰å…¨é—®é¢˜ï¼Œç¡®ä¿ç”¨æˆ·æ•°æ®å®‰å…¨")
            
        # é€»è¾‘å»ºè®®
        if any(i.get('severity') == 'high' for i in logic_issues):
            recommendations.append("ðŸ“‹ å®Œå–„æŠ€èƒ½æ–‡æ¡£ï¼Œç¡®ä¿ä½¿ç”¨åœºæ™¯æè¿°æ¸…æ™°")
            
        # é€šç”¨å»ºè®®
        if len(security_issues) + len(logic_issues) > 0:
            recommendations.append("ðŸ” å»ºè®®è¿›è¡Œå…¨é¢ä»£ç å®¡æŸ¥ï¼Œç¡®ä¿æŠ€èƒ½è´¨é‡å’Œå®‰å…¨æ€§")
            
        return recommendations

def calculate_file_hash(file_path: str) -> str:
    """è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼ç”¨äºŽç‰ˆæœ¬æ¯”è¾ƒ"""
    hash_md5 = hashlib.md5()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()

def compare_skill_versions(old_path: str, new_path: str) -> Dict[str, any]:
    """æ¯”è¾ƒæŠ€èƒ½ç‰ˆæœ¬å·®å¼‚"""
    old_hash = calculate_file_hash(old_path)
    new_hash = calculate_file_hash(new_path)
    
    return {
        'hash_changed': old_hash != new_hash,
        'old_hash': old_hash,
        'new_hash': new_hash,
        'timestamp': datetime.now().isoformat()
    }